I didnâ€™t expect that creating a plagiarism checker would be so difficult. It had thought it was a simple concept. I only needed to search for similar words between two text files, but finding a way to do this efficiently was the real challenge.

To simplify the problem, I defined a section of text as a consecutive grouping of words in a given file that contained a word count equal to a given search diameter. I then defined two text sections to be similar if they contained a large number of similar, but unique words. The first solution I thought of was to loop through all text sections from files 1 and 2, and count the number of words that are common to both sections. However, if the files contained 1020 words each and I used a search diameter of 20 words, the program would need to perform at least a million loops.

Fortunately, I could optimize the program by focusing only on words contained in both files. I used a dictionary to store and retrieve all instances of a given word within a file. Then, to find similarities, I only compared text sections from files 1 and 2 that were centered around a shared word. Although this strategy drastically reduces the amount of text comparisons, it does miss some possible matches. Also, this method performs worse when the input files contain lots of repeated words.
